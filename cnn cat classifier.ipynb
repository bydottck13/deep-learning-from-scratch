{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning from scratch\n",
    "## Convolutional Neural Networks for a cat classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import time as tm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Pre-processing images\n",
    "Skip this step after the first time running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dir = 'cat/'\n",
    "not_cat_dir = 'not-cat/'\n",
    "wolf_dir = 'wolf/'\n",
    "\n",
    "cat_files = [f for f in listdir(cat_dir) if isfile(join(cat_dir, f))]\n",
    "not_cat_files = [f for f in listdir(not_cat_dir) if isfile(join(not_cat_dir, f))]\n",
    "wolf_files = [f for f in listdir(wolf_dir) if isfile(join(wolf_dir, f))]\n",
    "\n",
    "width = 128\n",
    "height = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cat = []\n",
    "for filename in cat_files:\n",
    "    with Image.open(cat_dir+filename) as im:\n",
    "        if im.mode == 'RGB':\n",
    "            nim = im.resize((width, height), Image.BILINEAR)\n",
    "            pixel_values = np.array(nim.getdata()).reshape((width, height, 3))\n",
    "            x_cat.append(pixel_values)\n",
    "x_cat_array = np.array(x_cat)\n",
    "print(x_cat_array.shape)\n",
    "#plt.imshow(x_cat_array[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_not_cat = []\n",
    "for filename in not_cat_files:\n",
    "    with Image.open(not_cat_dir+filename) as im:\n",
    "        if im.mode == 'RGB':\n",
    "            nim = im.resize((width, height), Image.BILINEAR)\n",
    "            pixel_values = np.array(nim.getdata()).reshape((width, height, 3))\n",
    "            x_not_cat.append(pixel_values)\n",
    "x_not_cat_array = np.array(x_not_cat)\n",
    "print(x_not_cat_array.shape)\n",
    "#plt.imshow(x_not_cat_array[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_wolf = []\n",
    "for filename in wolf_files:\n",
    "    with Image.open(wolf_dir+filename) as im:\n",
    "        if im.mode == 'RGB':\n",
    "            nim = im.resize((width, height), Image.BILINEAR)\n",
    "            pixel_values = np.array(nim.getdata()).reshape((width, height, 3))\n",
    "            x_wolf.append(pixel_values)\n",
    "x_wolf_array = np.array(x_wolf)\n",
    "print(x_wolf_array.shape)\n",
    "#plt.imshow(x_wolf_array[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_array = []\n",
    "y_not_cat_array = np.zeros((x_not_cat_array.shape[0]+x_wolf_array.shape[0], 1))\n",
    "y_cat_array = np.ones((x_cat_array.shape[0], 1))\n",
    "\n",
    "y_array = np.append(y_not_cat_array, y_cat_array, axis=0)\n",
    "print(y_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_other_array = np.append(x_not_cat_array, x_wolf_array, axis=0)\n",
    "\n",
    "x_array = np.append(x_other_array, x_cat_array, axis=0)\n",
    "print(x_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the examples\n",
    "x_flatten = x_array.reshape(x_array.shape[0], -1).T # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "\n",
    "# Standardize data to have feature values between 0 and 1\n",
    "X = x_flatten/255.\n",
    "print(\"X's shape: \"+str(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save nympy arrays into files, for later usages\n",
    "X_file = 'X.npy'\n",
    "Y_file = 'Y.npy'\n",
    "\n",
    "np.save(X_file, X)\n",
    "np.save(Y_file, y_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Read Dataset from files\n",
    "Let's read data from X.npy and Y.npy that we previously prosessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X's shape: (49152, 4276)\n",
      "Y's shape: (1, 4276)\n"
     ]
    }
   ],
   "source": [
    "X = np.load('X.npy')\n",
    "Y = np.load('Y.npy').T\n",
    "print(\"X's shape: \"+str(X.shape))\n",
    "print(\"Y's shape: \"+str(Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffled_X's shape: (49152, 4276)\n",
      "shuffled_Y's shape: (1, 4276)\n"
     ]
    }
   ],
   "source": [
    "# Re-shuffle X and y_array\n",
    "permutation = list(np.random.permutation(X.shape[1]))\n",
    "shuffled_X = X[:, permutation]\n",
    "shuffled_Y = Y[:, permutation]\n",
    "\n",
    "print(\"shuffled_X's shape: \"+str(shuffled_X.shape))\n",
    "print(\"shuffled_Y's shape: \"+str(shuffled_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "#index = 4001\n",
    "#plt.imshow(X[:,index].reshape((128, 128, 3)))\n",
    "#print (\"y = \" + str(Y[0,index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 2566\n",
      "Number of developing examples: 855\n",
      "Number of testing examples: 855\n"
     ]
    }
   ],
   "source": [
    "m_test = np.rint(X.shape[1]*0.2).astype(int)\n",
    "m_dev = m_test\n",
    "m_train = X.shape[1]-m_test-m_dev\n",
    "print(\"Number of training examples: \" + str(m_train))\n",
    "print(\"Number of developing examples: \" + str(m_dev))\n",
    "print(\"Number of testing examples: \" + str(m_test))\n",
    "\n",
    "assert(m_test+m_dev+m_train==X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle with datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Data Sets|Percentage|\n",
    "|---|---|\n",
    "|Train set|80%|\n",
    "|Dev set|20%|\n",
    "|Test set|20%|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train's shape: (49152, 2566)\n",
      "y_train's shape: (1, 2566)\n"
     ]
    }
   ],
   "source": [
    "x_train = shuffled_X[:,0:m_train]\n",
    "y_train = shuffled_Y[:,0:m_train]\n",
    "x_dev = shuffled_X[:,m_train:m_train+m_dev]\n",
    "y_dev = shuffled_Y[:,m_train:m_train+m_dev]\n",
    "x_test = shuffled_X[:,m_train+m_dev:-1]\n",
    "y_test = shuffled_Y[:,m_train+m_dev:-1]\n",
    "\n",
    "print(\"x_train's shape: \"+str(x_train.shape))\n",
    "print(\"y_train's shape: \"+str(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "#plt.imshow(x_train[:,-1].reshape((128, 128, 3)))\n",
    "#print (\"y = \" + str(y_train[0,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x_dev[:,0].reshape((128, 128, 3)))\n",
    "#print (\"y = \" + str(y_dev[0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Deep Learning Model\n",
    "### 4.1 - Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ sigmoid( w^T x + b) = \\frac{1}{1 = e^{-(w^T x + b)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        Z -- numpy array of any shape\n",
    "    \n",
    "    Returns:\n",
    "        A -- output of sigmoid(z), same shape as Z\n",
    "        cache -- returns Z as well, useful during backpropagation\n",
    "    \"\"\"\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ReLU(Z) = max(0, Z)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        Z -- Output of the linear layer, of any shape\n",
    "    \n",
    "    Returns:\n",
    "        A -- Post-activation parameter, of the same shape as Z\n",
    "        cache -- a python dictionary containing \"A\"; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    A = np.maximum(0, Z)\n",
    "    cache = Z\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        dA -- post-activation gradient, of any shape\n",
    "        cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "    \n",
    "    Returns:\n",
    "        dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        dA -- post-activation gradient, of any shape\n",
    "        cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "    \n",
    "    Returns:\n",
    "        dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    dZ[Z <= 0] = 0\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Initialization\n",
    "#### a) two-layer initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size of input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing parameters:\n",
    "        W1 -- weight matrix of shape (n_h, n_x)\n",
    "        b1 -- bias vector of shape (n_h, 1)\n",
    "        W2 -- weight matrix of shape (n_y, n_h)\n",
    "        b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    W1 = np.random.randn(n_h, n_x)*0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h)*0.01\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\":W1,\n",
    "                  \"b1\":b1,\n",
    "                  \"W2\":W2,\n",
    "                  \"b2\":b2}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) L-layer initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "        parameters -- python dictionary containing parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                W1 -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                b1 -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    parameters = {}\n",
    "    L = len(layer_dims) # number of layers in the network\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters['W'+str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])*0.01\n",
    "        parameters['b'+str(l)] = np.zeros((layer_dims[l], 1))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Forward propagation module\n",
    "$$Z^{[l]} = W^{[l]}A^{[l-1]} + b^{[l]}$$\n",
    "where $A^{[0]} = X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        A -- activations from previous layer\n",
    "        W -- weights matrix\n",
    "        b -- bias vector\n",
    "    \n",
    "    Returns:\n",
    "        Z -- the input of the activation function\n",
    "        cache -- a python dictionary containing \"A\", \"W\" and \"b\"\n",
    "    \"\"\"\n",
    "    Z = np.dot(W, A)+b\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Sigmoid**: $\\sigma(Z) = \\sigma(W A + b) = \\frac{1}{ 1 + e^{-(W A + b)}}$\n",
    "- **ReLU**: $A = RELU(Z) = max(0, Z)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "        W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "        b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "        activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "        A -- the input of the activation function, also called the post-activation value\n",
    "        cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\"; \n",
    "                 stored for computing the backward pass effeciently\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "        \n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L-layer activation forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        X -- data, numpy array of shape (input size, number of examples)\n",
    "        parameters -- output of initialize_parameter_deep()\n",
    "    \n",
    "    Returns:\n",
    "        AL -- last post-activation value\n",
    "        caches -- list of caches containing:\n",
    "                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n",
    "                the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n",
    "    \"\"\"\n",
    "    \n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W'+str(l)], parameters['b'+str(l)], activation = \"relu\")\n",
    "        caches.append(cache)\n",
    "    AL, cache = linear_activation_forward(A, parameters['W'+str(L)], parameters['b'+str(L)], activation = \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "\n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 - Cost function\n",
    "$$J = -\\frac{1}{m} \\sum\\limits_{i = 1}^{m}(y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L] (i)}\\right))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        AL -- probability vector corresponding to label predictions, shape (1, number of examples)\n",
    "        Y -- true \"label\" vector, shape (1, number of examples)\n",
    "\n",
    "    Returns:\n",
    "        cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    cost = (-1/m)*np.sum(np.multiply(np.log(AL), Y)+np.multiply(np.log(1-AL),(1-Y)))\n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 - Backward propagation module\n",
    "$$ dW^{[l]} = \\frac{\\partial \\mathcal{L} }{\\partial W^{[l]}} = \\frac{1}{m} dZ^{[L]} A^{[l-1] T}$$\n",
    "$$ db^{[l]} = \\frac{\\partial \\mathcal{L} }{\\partial b^{[l]}} = \\frac{1}{m} \\sum\\limits_{i = 1}^{m} dZ^{[l](i)}$$\n",
    "$$ dA^{[l-1]} = \\frac{\\partial \\mathcal{L}}{\\partial A^{[l-1]}} = W^{[l] T} dZ^{[l]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "        cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "    \n",
    "    Returns:\n",
    "        dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "        dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "        db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    dW = 1/m*np.dot(dZ, A_prev.T)\n",
    "    db = 1/m*np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$dZ^{[l]} = dA^{[l]} * g'(Z^{[l]})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        dA -- post-activation gradient for current layer l\n",
    "        cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "        activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "        \n",
    "    Returns:\n",
    "        dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "        dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "        db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L-layer activation backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "        Y -- true \"label\" vector\n",
    "        caches -- list of caches cantaining:\n",
    "                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e. l = 0...L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n",
    "    \n",
    "    Returns:\n",
    "        grads -- A dictionary with the gradients\n",
    "            grads[\"dA\"+str(l)] = ...\n",
    "            grads[\"dW\"+str(l)] = ...\n",
    "            grads[\"db\"+str(l)] = ...\n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    \n",
    "    dAL = -(np.divide(Y, AL) - np.divide(1-Y, 1-AL))\n",
    "    \n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\"+str(L-1)], grads[\"dW\"+str(L)], grads[\"db\"+str(L)] = linear_activation_backward(dAL, current_cache, \"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\"+str(l+1)], current_cache, \"relu\")\n",
    "        grads[\"dA\"+str(l)] = dA_prev_temp\n",
    "        grads[\"dW\"+str(l+1)] = dW_temp\n",
    "        grads[\"db\"+str(l+1)] = db_temp\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 - Update Parameters\n",
    "$$ W^{[l]} = W^{[l]} - \\alpha \\text{ } dW^{[l]}$$\n",
    "$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        parameters -- python dictionary containing parameters\n",
    "        grads -- python dictionary containing gradients, output of L_model_backward\n",
    "        \n",
    "    Returns:\n",
    "        parameters -- python dictionary containing updated parameters\n",
    "    \"\"\"\n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "    \n",
    "    for l in range(L):\n",
    "        parameters[\"W\"+str(l+1)] = parameters[\"W\"+str(l+1)] - learning_rate*grads[\"dW\"+str(l+1)]\n",
    "        parameters[\"b\"+str(l+1)] = parameters[\"b\"+str(l+1)] - learning_rate*grads[\"db\"+str(l+1)]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 - Two-layer neural network\n",
    "- *LINEAR -> RELU -> LINEAR -> SIGMOID*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        X -- input data, of shape (n_x, number of examples)\n",
    "        Y -- true \"label\" vector (containing 0 if cat, 1 if not-cat), of shape (1, number of examples)\n",
    "        layer_dims -- dimensions of the layers (n_x, n_h, n_y)\n",
    "        num_iterations -- number of iterations of the optimization loop\n",
    "        learning_rate -- learning rate of the gradient descent update rule\n",
    "        print_cost -- If set to True, this will print the cost every 100 iterations\n",
    "        \n",
    "    Returns:\n",
    "        parameters -- a dictionary containing W1, W2, b1 and b2\n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    costs = [] # to keep track of the cost\n",
    "    m = X.shape[1] # number of examples\n",
    "    (n_x, n_h, n_y) = layers_dims\n",
    "    \n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    \n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        A1, cache1 = linear_activation_forward(X, W1, b1, \"relu\")\n",
    "        A2, cache2 = linear_activation_forward(A1, W2, b2, \"sigmoid\")\n",
    "        cost = compute_cost(A2, Y)\n",
    "        \n",
    "        dA2 = -(np.divide(Y, A2) - np.divide(1-Y, 1-A2))\n",
    "        dA1, dW2, db2 = linear_activation_backward(dA2, cache2, \"sigmoid\")\n",
    "        dA0, dW1, db1 = linear_activation_backward(dA1, cache1, \"relu\")\n",
    "        \n",
    "        grads['dW1'] = dW1\n",
    "        grads['db1'] = db1\n",
    "        grads['dW2'] = dW2\n",
    "        grads['db2'] = db2\n",
    "        \n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        W1 = parameters[\"W1\"]\n",
    "        b1 = parameters[\"b1\"]\n",
    "        W2 = parameters[\"W2\"]\n",
    "        b2 = parameters[\"b2\"]\n",
    "        \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "    \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('costs')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\"+str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 - L-layer Neural Network\n",
    "- *[LINEAR -> RELU]X(L-1) -> LINEAR -> SIGMOID*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        X -- data, numpy array of shape (number of examples, num_px*num_px*3)\n",
    "        Y -- true \"label\" vector\n",
    "        layer_dims -- dimensions of the layers (n_x, n_h, n_y)\n",
    "        num_iterations -- number of iterations of the optimization loop\n",
    "        learning_rate -- learning rate of the gradient descent update rule\n",
    "        print_cost -- If set to True, this will print the cost every 100 iterations\n",
    "        \n",
    "    Returns:\n",
    "        parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = [] # keep track of cost\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        cost = compute_cost(AL, Y)\n",
    "        \n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('costs')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\"+str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9 - Train the model\n",
    "For developing the model, use *x_dev*. For training the model, use *x_train*.\n",
    "This step will take some time which depends on the performance of the CPU/GPU.\n",
    "\n",
    "#### a) 2-layer model\n",
    "This will take about 26mins with the dev-set on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constants ###\n",
    "n_x = x_dev.shape[0] # 128*128*3\n",
    "n_h = 7\n",
    "n_y = 1\n",
    "layers_dims = (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6925377564547899\n",
      "Cost after iteration 100: 0.6403119471040984\n",
      "Cost after iteration 200: 0.6141009095109112\n",
      "Cost after iteration 300: 0.578848886356996\n",
      "Cost after iteration 400: 0.5716852690376716\n",
      "Cost after iteration 500: 0.5485775527875739\n",
      "Cost after iteration 600: 0.5323422171244285\n",
      "Cost after iteration 700: 0.5264398603718514\n",
      "Cost after iteration 800: 0.5149561033603194\n",
      "Cost after iteration 900: 0.5201601692274014\n",
      "Cost after iteration 1000: 0.5101695554362957\n",
      "Cost after iteration 1100: 0.4808560108219037\n",
      "Cost after iteration 1200: 0.46261273168075867\n",
      "Cost after iteration 1300: 0.4788402740545385\n",
      "Cost after iteration 1400: 0.4325995169391231\n",
      "Cost after iteration 1500: 0.4342824237720148\n",
      "Cost after iteration 1600: 0.4305241528656801\n",
      "Cost after iteration 1700: 0.38707790806092846\n",
      "Cost after iteration 1800: 0.4083022986232553\n",
      "Cost after iteration 1900: 0.3815096754543617\n",
      "Cost after iteration 2000: 0.3667546297162329\n",
      "Cost after iteration 2100: 0.37513232561407184\n",
      "Cost after iteration 2200: 0.33193710309381425\n",
      "Cost after iteration 2300: 0.32629618733966104\n",
      "Cost after iteration 2400: 0.3694624171709419\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4148.566482543945 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = tm.time()\n",
    "parameters_2L = two_layer_model(x_dev, y_dev, layers_dims=(n_x, n_h, n_y), num_iterations=2500, print_cost=True)\n",
    "print(\"--- %s seconds ---\" %(tm.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> **Cost after iteration 0**</td>\n",
    "        <td> 0.69...... </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **...**</td>\n",
    "        <td> ... </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **Cost after iteration 2400**</td>\n",
    "        <td> 0.35...... </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) L-layer model\n",
    "This will take about 33mins with the dev-set on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constants ###\n",
    "layers_dims = [x_dev.shape[0], 20, 7, 5, 1] # 4-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6931432087655532\n",
      "Cost after iteration 100: 0.6747616467093338\n",
      "Cost after iteration 200: 0.6621167584650529\n",
      "Cost after iteration 300: 0.6533930730351684\n",
      "Cost after iteration 400: 0.6473521952963528\n",
      "Cost after iteration 500: 0.643152428543547\n",
      "Cost after iteration 600: 0.64022125643104\n",
      "Cost after iteration 700: 0.6381680232206409\n",
      "Cost after iteration 800: 0.6367250093182889\n",
      "Cost after iteration 900: 0.6357078675948494\n",
      "Cost after iteration 1000: 0.6349890525775911\n",
      "Cost after iteration 1100: 0.6344799173646423\n",
      "Cost after iteration 1200: 0.6341185923353322\n",
      "Cost after iteration 1300: 0.6338617333218981\n",
      "Cost after iteration 1400: 0.6336788727972505\n",
      "Cost after iteration 1500: 0.6335485308975363\n",
      "Cost after iteration 1600: 0.6334555255085822\n",
      "Cost after iteration 1700: 0.6333891014484728\n",
      "Cost after iteration 1800: 0.6333416250194905\n",
      "Cost after iteration 1900: 0.6333076688985888\n",
      "Cost after iteration 2000: 0.6332833691233526\n",
      "Cost after iteration 2100: 0.6332659714341489\n",
      "Cost after iteration 2200: 0.633253510141537\n",
      "Cost after iteration 2300: 0.6332445813617503\n",
      "Cost after iteration 2400: 0.6332381817635787\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2010.272352695465 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = tm.time()\n",
    "parameters_NL = L_layer_model(x_dev, y_dev, layers_dims, num_iterations=2500, print_cost=True)\n",
    "print(\"--- %s seconds ---\" %(tm.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> **Cost after iteration 0**</td>\n",
    "        <td> 0.69...... </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **...**</td>\n",
    "        <td> ... </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **Cost after iteration 2400**</td>\n",
    "        <td> 0.63...... </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.10 -- Calculate the accurancy of the predicting results\n",
    "Predict the results and the accuracy rate.\n",
    "$$\\hat{Y} = A = \\sigma(w^T X + b)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        X -- data set of examples\n",
    "        parameters -- parameters of the trained model\n",
    "    \n",
    "    Returns:\n",
    "        p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "    \n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "            \n",
    "    print(\"Accuracy: \"+str(np.sum((p==y)/m)))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8385964912280699\n"
     ]
    }
   ],
   "source": [
    "pred_2L_dev = predict(x_dev, y_dev, parameters_2L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_NL_dev = predict(x_dev, y_dev, parameters_NL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Train the model with training data\n",
    "### 5.1 2-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constants ###\n",
    "n_x = x_train.shape[0] # 128*128*3\n",
    "n_h = 7\n",
    "n_y = 1\n",
    "layers_dims = (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = tm.time()\n",
    "parameters_2L_t = two_layer_model(x_train, y_train, layers_dims=(n_x, n_h, n_y), num_iterations=2500, print_cost=True)\n",
    "print(\"--- %s seconds ---\" %(tm.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 L-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constants ###\n",
    "layers_dims = [x_train.shape[0], 20, 7, 5, 1] # 4-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = tm.time()\n",
    "parameters_NL_t = L_layer_model(x_train, y_train, layers_dims, num_iterations=2500, print_cost=True)\n",
    "print(\"--- %s seconds ---\" %(tm.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Accuracy rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2L_train = predict(x_train, y_train, parameters_2L_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_NL_train = predict(x_train, y_train, parameters_2L_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Verify with testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2L_test = predict(x_test, y_test, parameters_2L_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_NL_test = predict(x_train, y_train, parameters_2L_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
