{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning from scratch\n",
    "## Convolutional Neural Networks for cat classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import time as tm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Pre-processing images\n",
    "Skip this step after the first time running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dir = 'cat/'\n",
    "not_cat_dir = 'not-cat/'\n",
    "wolf_dir = 'wolf/'\n",
    "\n",
    "cat_files = [f for f in listdir(cat_dir) if isfile(join(cat_dir, f))]\n",
    "not_cat_files = [f for f in listdir(not_cat_dir) if isfile(join(not_cat_dir, f))]\n",
    "wolf_files = [f for f in listdir(wolf_dir) if isfile(join(wolf_dir, f))]\n",
    "\n",
    "width = 128\n",
    "height = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cat = []\n",
    "for filename in cat_files:\n",
    "    with Image.open(cat_dir+filename) as im:\n",
    "        if im.mode == 'RGB':\n",
    "            nim = im.resize((width, height), Image.BILINEAR)\n",
    "            pixel_values = np.array(nim.getdata()).reshape((width, height, 3))\n",
    "            x_cat.append(pixel_values)\n",
    "x_cat_array = np.array(x_cat)\n",
    "print(x_cat_array.shape)\n",
    "#plt.imshow(x_cat_array[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_not_cat = []\n",
    "for filename in not_cat_files:\n",
    "    with Image.open(not_cat_dir+filename) as im:\n",
    "        if im.mode == 'RGB':\n",
    "            nim = im.resize((width, height), Image.BILINEAR)\n",
    "            pixel_values = np.array(nim.getdata()).reshape((width, height, 3))\n",
    "            x_not_cat.append(pixel_values)\n",
    "x_not_cat_array = np.array(x_not_cat)\n",
    "print(x_not_cat_array.shape)\n",
    "#plt.imshow(x_not_cat_array[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_wolf = []\n",
    "for filename in wolf_files:\n",
    "    with Image.open(wolf_dir+filename) as im:\n",
    "        if im.mode == 'RGB':\n",
    "            nim = im.resize((width, height), Image.BILINEAR)\n",
    "            pixel_values = np.array(nim.getdata()).reshape((width, height, 3))\n",
    "            x_wolf.append(pixel_values)\n",
    "x_wolf_array = np.array(x_wolf)\n",
    "print(x_wolf_array.shape)\n",
    "#plt.imshow(x_wolf_array[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_array = []\n",
    "y_not_cat_array = np.zeros((x_not_cat_array.shape[0]+x_wolf_array.shape[0], 1))\n",
    "y_cat_array = np.ones((x_cat_array.shape[0], 1))\n",
    "\n",
    "y_array = np.append(y_not_cat_array, y_cat_array, axis=0)\n",
    "print(y_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_other_array = np.append(x_not_cat_array, x_wolf_array, axis=0)\n",
    "\n",
    "x_array = np.append(x_other_array, x_cat_array, axis=0)\n",
    "print(x_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the examples\n",
    "x_flatten = x_array.reshape(x_array.shape[0], -1).T # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "\n",
    "# Standardize data to have feature values between 0 and 1\n",
    "X = x_flatten/255.\n",
    "print(\"X's shape: \"+str(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save nympy arrays into files, for later usages\n",
    "X_file = 'X.npy'\n",
    "Y_file = 'Y.npy'\n",
    "\n",
    "np.save(X_file, X)\n",
    "np.save(Y_file, y_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Read Dataset from files\n",
    "Let's read data from X.npy and Y.npy that we previously prosessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X's shape: (49152, 4276)\n",
      "Y's shape: (1, 4276)\n"
     ]
    }
   ],
   "source": [
    "X = np.load('X.npy')\n",
    "Y = np.load('Y.npy').T\n",
    "print(\"X's shape: \"+str(X.shape))\n",
    "print(\"Y's shape: \"+str(Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffled_X's shape: (49152, 4276)\n",
      "shuffled_Y's shape: (1, 4276)\n"
     ]
    }
   ],
   "source": [
    "# Re-shuffle X and y_array\n",
    "permutation = list(np.random.permutation(X.shape[1]))\n",
    "shuffled_X = X[:, permutation]\n",
    "shuffled_Y = Y[:, permutation]\n",
    "\n",
    "print(\"shuffled_X's shape: \"+str(shuffled_X.shape))\n",
    "print(\"shuffled_Y's shape: \"+str(shuffled_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "#index = 4001\n",
    "#plt.imshow(X[:,index].reshape((128, 128, 3)))\n",
    "#print (\"y = \" + str(Y[0,index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 2566\n",
      "Number of developing examples: 855\n",
      "Number of testing examples: 855\n"
     ]
    }
   ],
   "source": [
    "m_test = np.rint(X.shape[1]*0.2).astype(int)\n",
    "m_dev = m_test\n",
    "m_train = x_array.shape[0]-m_test-m_dev\n",
    "print(\"Number of training examples: \" + str(m_train))\n",
    "print(\"Number of developing examples: \" + str(m_dev))\n",
    "print(\"Number of testing examples: \" + str(m_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle with datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Data Sets|Percentage|\n",
    "|---|---|\n",
    "|Train set|80%|\n",
    "|Dev set|20%|\n",
    "|Test set|20%|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train's shape: (49152, 2566)\n",
      "y_train's shape: (1, 2566)\n"
     ]
    }
   ],
   "source": [
    "x_train = shuffled_X[:,0:m_train]\n",
    "y_train = shuffled_Y[:,0:m_train]\n",
    "x_dev = shuffled_X[:,m_train:m_train+m_dev]\n",
    "y_dev = shuffled_Y[:,m_train:m_train+m_dev]\n",
    "x_test = shuffled_X[:,m_train+m_dev:-1]\n",
    "y_test = shuffled_Y[:,m_train+m_dev:-1]\n",
    "\n",
    "print(\"x_train's shape: \"+str(x_train.shape))\n",
    "print(\"y_train's shape: \"+str(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "#plt.imshow(x_train[:,-1].reshape((128, 128, 3)))\n",
    "#print (\"y = \" + str(y_train[0,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x_dev[:,0].reshape((128, 128, 3)))\n",
    "#print (\"y = \" + str(y_dev[0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Deep Learning Model\n",
    "### 4.1 - Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ sigmoid( w^T x + b) = \\frac{1}{1 = e^{-(w^T x + b)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        Z -- numpy array of any shape\n",
    "    \n",
    "    Returns:\n",
    "        A -- output of sigmoid(z), same shape as Z\n",
    "        cache -- returns Z as well, useful during backpropagation\n",
    "    \"\"\"\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ReLU(Z) = max(0, Z)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        Z -- Output of the linear layer, of any shape\n",
    "    \n",
    "    Returns:\n",
    "        A -- Post-activation parameter, of the same shape as Z\n",
    "        cache -- a python dictionary containing \"A\"; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    A = np.maximum(0, Z)\n",
    "    cache = Z\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        dA -- post-activation gradient, of any shape\n",
    "        cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "    \n",
    "    Returns:\n",
    "        dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        dA -- post-activation gradient, of any shape\n",
    "        cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "    \n",
    "    Returns:\n",
    "        dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    dZ[Z <= 0] = 0\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Initialization\n",
    "#### a) two-layer initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size of input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing parameters:\n",
    "        W1 -- weight matrix of shape (n_h, n_x)\n",
    "        b1 -- bias vector of shape (n_h, 1)\n",
    "        W2 -- weight matrix of shape (n_y, n_h)\n",
    "        b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    W1 = np.random.randn(n_h, n_x)*0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h)*0.01\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\":W1,\n",
    "                  \"b1\":b1,\n",
    "                  \"W2\":W2,\n",
    "                  \"b2\":b2}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) L-layer initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "        parameters -- python dictionary containing parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                W1 -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                b1 -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    parameters = {}\n",
    "    L = len(layer_dims) # number of layers in the network\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters['W'+str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])*0.01\n",
    "        parameters['b'+str(l)] = np.zeros((layer_dims[l], 1))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Forward propagation module\n",
    "$$Z^{[l]} = W^{[l]}A^{[l-1]} + b^{[l]}$$\n",
    "where $A^{[0]} = X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        A -- activations from previous layer\n",
    "        W -- weights matrix\n",
    "        b -- bias vector\n",
    "    \n",
    "    Returns:\n",
    "        Z -- the input of the activation function\n",
    "        cache -- a python dictionary containing \"A\", \"W\" and \"b\"\n",
    "    \"\"\"\n",
    "    Z = np.dot(W, A)+b\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Sigmoid**: $\\sigma(Z) = \\sigma(W A + b) = \\frac{1}{ 1 + e^{-(W A + b)}}$\n",
    "- **ReLU**: $A = RELU(Z) = max(0, Z)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "        W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "        b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "        activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "        A -- the input of the activation function, also called the post-activation value\n",
    "        cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\"; \n",
    "                 stored for computing the backward pass effeciently\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "        \n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L-layer activation forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        X -- data, numpy array of shape (input size, number of examples)\n",
    "        parameters -- output of initialize_parameter_deep()\n",
    "    \n",
    "    Returns:\n",
    "        AL -- last post-activation value\n",
    "        caches -- list of caches containing:\n",
    "                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n",
    "                the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n",
    "    \"\"\"\n",
    "    \n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W'+str(l)], parameters['b'+str(l)], activation = \"relu\")\n",
    "        caches.append(cache)\n",
    "    AL, cache = linear_activation_forward(A, parameters['W'+str(L)], parameters['b'+str(L)], activation = \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "\n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 - Cost function\n",
    "$$J = -\\frac{1}{m} \\sum\\limits_{i = 1}^{m}(y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L] (i)}\\right))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        AL -- probability vector corresponding to label predictions, shape (1, number of examples)\n",
    "        Y -- true \"label\" vector, shape (1, number of examples)\n",
    "\n",
    "    Returns:\n",
    "        cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    cost = (-1/m)*np.sum(np.multiply(np.log(AL), Y)+np.multiply(np.log(1-AL),(1-Y)))\n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 - Backward propagation module\n",
    "$$ dW^{[l]} = \\frac{\\partial \\mathcal{L} }{\\partial W^{[l]}} = \\frac{1}{m} dZ^{[L]} A^{[l-1] T}$$\n",
    "$$ db^{[l]} = \\frac{\\partial \\mathcal{L} }{\\partial b^{[l]}} = \\frac{1}{m} \\sum\\limits_{i = 1}^{m} dZ^{[l](i)}$$\n",
    "$$ dA^{[l-1]} = \\frac{\\partial \\mathcal{L}}{\\partial A^{[l-1]}} = W^{[l] T} dZ^{[l]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "        cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "    \n",
    "    Returns:\n",
    "        dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "        dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "        db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    dW = 1/m*np.dot(dZ, A_prev.T)\n",
    "    db = 1/m*np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$dZ^{[l]} = dA^{[l]} * g'(Z^{[l]})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        dA -- post-activation gradient for current layer l\n",
    "        cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "        activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "        \n",
    "    Returns:\n",
    "        dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "        dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "        db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L-layer activation backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "        Y -- true \"label\" vector\n",
    "        caches -- list of caches cantaining:\n",
    "                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e. l = 0...L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n",
    "    \n",
    "    Returns:\n",
    "        grads -- A dictionary with the gradients\n",
    "            grads[\"dA\"+str(l)] = ...\n",
    "            grads[\"dW\"+str(l)] = ...\n",
    "            grads[\"db\"+str(l)] = ...\n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    \n",
    "    dAL = -(np.divide(Y, AL) - np.divide(1-Y, 1-AL))\n",
    "    \n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\"+str(L-1)], grads[\"dW\"+str(L)], grads[\"db\"+str(L)] = linear_activation_backward(dAL, current_cache, \"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\"+str(l+1)], current_cache, \"relu\")\n",
    "        grads[\"dA\"+str(l)] = dA_prev_temp\n",
    "        grads[\"dW\"+str(l+1)] = dW_temp\n",
    "        grads[\"db\"+str(l+1)] = db_temp\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 - Update Parameters\n",
    "$$ W^{[l]} = W^{[l]} - \\alpha \\text{ } dW^{[l]}$$\n",
    "$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        parameters -- python dictionary containing parameters\n",
    "        grads -- python dictionary containing gradients, output of L_model_backward\n",
    "        \n",
    "    Returns:\n",
    "        parameters -- python dictionary containing updated parameters\n",
    "    \"\"\"\n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "    \n",
    "    for l in range(L):\n",
    "        parameters[\"W\"+str(l+1)] = parameters[\"W\"+str(l+1)] - learning_rate*grads[\"dW\"+str(l+1)]\n",
    "        parameters[\"b\"+str(l+1)] = parameters[\"b\"+str(l+1)] - learning_rate*grads[\"db\"+str(l+1)]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 - Two-layer neural network\n",
    "- *LINEAR -> RELU -> LINEAR -> SIGMOID*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        X -- input data, of shape (n_x, number of examples)\n",
    "        Y -- true \"label\" vector (containing 0 if cat, 1 if not-cat), of shape (1, number of examples)\n",
    "        layer_dims -- dimensions of the layers (n_x, n_h, n_y)\n",
    "        num_iterations -- number of iterations of the optimization loop\n",
    "        learning_rate -- learning rate of the gradient descent update rule\n",
    "        print_cost -- If set to True, this will print the cost every 100 iterations\n",
    "        \n",
    "    Returns:\n",
    "        parameters -- a dictionary containing W1, W2, b1 and b2\n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    costs = [] # to keep track of the cost\n",
    "    m = X.shape[1] # number of examples\n",
    "    (n_x, n_h, n_y) = layers_dims\n",
    "    \n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    \n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        A1, cache1 = linear_activation_forward(X, W1, b1, \"relu\")\n",
    "        A2, cache2 = linear_activation_forward(A1, W2, b2, \"sigmoid\")\n",
    "        cost = compute_cost(A2, Y)\n",
    "        \n",
    "        dA2 = -(np.divide(Y, A2) - np.divide(1-Y, 1-A2))\n",
    "        dA1, dW2, db2 = linear_activation_backward(dA2, cache2, \"sigmoid\")\n",
    "        dA0, dW1, db1 = linear_activation_backward(dA1, cache1, \"relu\")\n",
    "        \n",
    "        grads['dW1'] = dW1\n",
    "        grads['db1'] = db1\n",
    "        grads['dW2'] = dW2\n",
    "        grads['db2'] = db2\n",
    "        \n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        W1 = parameters[\"W1\"]\n",
    "        b1 = parameters[\"b1\"]\n",
    "        W2 = parameters[\"W2\"]\n",
    "        b2 = parameters[\"b2\"]\n",
    "        \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "    \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('costs')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\"+str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 - L-layer Neural Network\n",
    "- *[LINEAR -> RELU]X(L-1) -> LINEAR -> SIGMOID*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        X -- data, numpy array of shape (number of examples, num_px*num_px*3)\n",
    "        Y -- true \"label\" vector\n",
    "        layer_dims -- dimensions of the layers (n_x, n_h, n_y)\n",
    "        num_iterations -- number of iterations of the optimization loop\n",
    "        learning_rate -- learning rate of the gradient descent update rule\n",
    "        print_cost -- If set to True, this will print the cost every 100 iterations\n",
    "        \n",
    "    Returns:\n",
    "        parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = [] # keep track of cost\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        cost = compute_cost(AL, Y)\n",
    "        \n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('costs')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\"+str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9 - Train the model\n",
    "For developing the model, use *x_dev*. For training the model, use *x_train*.\n",
    "This step will take some time which depends on the performance of the CPU/GPU.\n",
    "\n",
    "#### a) 2-layer model\n",
    "This will take about 26mins with the dev-set on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constants ###\n",
    "n_x = x_dev.shape[0] # 128*128*3\n",
    "n_h = 7\n",
    "n_y = 1\n",
    "layers_dims = (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6938863538855886\n",
      "Cost after iteration 100: 0.6254899162497122\n",
      "Cost after iteration 200: 0.6091962478417029\n",
      "Cost after iteration 300: 0.5892282241723223\n",
      "Cost after iteration 400: 0.5624153092029219\n",
      "Cost after iteration 500: 0.5713061424708021\n",
      "Cost after iteration 600: 0.5594848867194964\n",
      "Cost after iteration 700: 0.5424121221276851\n",
      "Cost after iteration 800: 0.5202173601450247\n",
      "Cost after iteration 900: 0.5219754611223384\n",
      "Cost after iteration 1000: 0.5045027731654943\n",
      "Cost after iteration 1100: 0.49489547117582944\n",
      "Cost after iteration 1200: 0.48754038343756895\n",
      "Cost after iteration 1300: 0.47270381163328806\n",
      "Cost after iteration 1400: 0.4627236617863442\n",
      "Cost after iteration 1500: 0.4531441614681022\n",
      "Cost after iteration 1600: 0.441785921032767\n",
      "Cost after iteration 1700: 0.4277278717811122\n",
      "Cost after iteration 1800: 0.41752633039299875\n",
      "Cost after iteration 1900: 0.411517948567082\n",
      "Cost after iteration 2000: 0.3992529761710904\n",
      "Cost after iteration 2100: 0.3732093513758977\n",
      "Cost after iteration 2200: 0.3719881389955367\n",
      "Cost after iteration 2300: 0.36731814813717584\n",
      "Cost after iteration 2400: 0.35385382816618893\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1592.4660222530365 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = tm.time()\n",
    "parameters_2L = two_layer_model(x_dev, y_dev, layers_dims=(n_x, n_h, n_y), num_iterations=2500, print_cost=True)\n",
    "print(\"--- %s seconds ---\" %(tm.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> **Cost after iteration 0**</td>\n",
    "        <td> 0.69...... </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **...**</td>\n",
    "        <td> ... </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **Cost after iteration 2400**</td>\n",
    "        <td> 0.35...... </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) L-layer model\n",
    "This will take about 33mins with the dev-set on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constants ###\n",
    "layers_dims = [x_dev.shape[0], 20, 7, 5, 1] # 4-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6931432087655532\n",
      "Cost after iteration 100: 0.6747616467093338\n",
      "Cost after iteration 200: 0.6621167584650529\n",
      "Cost after iteration 300: 0.6533930730351684\n",
      "Cost after iteration 400: 0.6473521952963528\n",
      "Cost after iteration 500: 0.643152428543547\n",
      "Cost after iteration 600: 0.64022125643104\n",
      "Cost after iteration 700: 0.6381680232206409\n",
      "Cost after iteration 800: 0.6367250093182889\n",
      "Cost after iteration 900: 0.6357078675948494\n",
      "Cost after iteration 1000: 0.6349890525775911\n",
      "Cost after iteration 1100: 0.6344799173646423\n",
      "Cost after iteration 1200: 0.6341185923353322\n",
      "Cost after iteration 1300: 0.6338617333218981\n",
      "Cost after iteration 1400: 0.6336788727972505\n",
      "Cost after iteration 1500: 0.6335485308975363\n",
      "Cost after iteration 1600: 0.6334555255085822\n",
      "Cost after iteration 1700: 0.6333891014484728\n",
      "Cost after iteration 1800: 0.6333416250194905\n",
      "Cost after iteration 1900: 0.6333076688985888\n",
      "Cost after iteration 2000: 0.6332833691233526\n",
      "Cost after iteration 2100: 0.6332659714341489\n",
      "Cost after iteration 2200: 0.633253510141537\n",
      "Cost after iteration 2300: 0.6332445813617503\n",
      "Cost after iteration 2400: 0.6332381817635787\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2010.272352695465 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = tm.time()\n",
    "parameters_NL = L_layer_model(x_dev, y_dev, layers_dims, num_iterations=2500, print_cost=True)\n",
    "print(\"--- %s seconds ---\" %(tm.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> **Cost after iteration 0**</td>\n",
    "        <td> 0.69...... </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **...**</td>\n",
    "        <td> ... </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **Cost after iteration 2400**</td>\n",
    "        <td> 0.63...... </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.10 -- Calculate the accurancy of the predicting results\n",
    "Predict the results and the accuracy rate.\n",
    "$$\\hat{Y} = A = \\sigma(w^T X + b)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        X -- data set of examples\n",
    "        parameters -- parameters of the trained model\n",
    "    \n",
    "    Returns:\n",
    "        p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "    \n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "            \n",
    "    print(\"Accuracy: \"+str(np.sum((p==y)/m)))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8385964912280699\n"
     ]
    }
   ],
   "source": [
    "pred_2L_dev = predict(x_dev, y_dev, parameters_2L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_NL_dev = predict(x_dev, y_dev, parameters_NL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Train the model with training data\n",
    "### 5.1 2-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constants ###\n",
    "n_x = x_train.shape[0] # 128*128*3\n",
    "n_h = 7\n",
    "n_y = 1\n",
    "layers_dims = (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = tm.time()\n",
    "parameters_2L_t = two_layer_model(x_train, y_train, layers_dims=(n_x, n_h, n_y), num_iterations=2500, print_cost=True)\n",
    "print(\"--- %s seconds ---\" %(tm.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 L-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constants ###\n",
    "layers_dims = [x_train.shape[0], 20, 7, 5, 1] # 4-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = tm.time()\n",
    "parameters_NL_t = L_layer_model(x_train, y_train, layers_dims, num_iterations=2500, print_cost=True)\n",
    "print(\"--- %s seconds ---\" %(tm.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Accuracy rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2L_train = predict(x_train, y_train, parameters_2L_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_NL_train = predict(x_train, y_train, parameters_2L_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Verify with testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2L_test = predict(x_test, y_test, parameters_2L_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_NL_test = predict(x_train, y_train, parameters_2L_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
